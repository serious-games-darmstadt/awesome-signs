# awesome-signs

[About me](https://www.etit.tu-darmstadt.de/serious-games/willkommen_sg/team_sg/team_sg_details_106944.de.jsp)

## Databases

- ASL-LEX

## Publications

### Towards handshape identification for automatic gesture recognition using sign notation systems
<details>
  <summary>Read more</summary>
  **Abstract**: Today, about 72 million people worldwide are speaking sign language. Since many deaf people are also dumb, they cannot communicate with hearing people through spoken language, even if they can lip-read. But sign language is difficult to learn, and more than 300 different sign languages in the world make things even more challenging. Therefore, to support the learning of sign language, we want to develop a gamified learning app for sign language that includes automatic sign recognition. The application should provide constructive feedback to the user about the quality of the executed sign. Each sign could be parameterised in terms of its characteristic handshape and its orientation and position: the more parameters are available, the more accurate and detailed feedback can be provided for the user. However, the parameters must also be distinguishable from a technical point of view.
  In linguistics, different notation systems exist to translate signs into written form. For this, the systems decompose signs into their characteristic properties. We want to utilise these notation systems to reduce signs to parameters that are easy to measure, e.g., the hand's shape, orientation, or position. Since the sign notation systems originate from different fields and have different backgrounds, they also differ in their objectives and thus in numbers and extents of parameters and respective features, further called symbols. Therefore, there are systems whose notations have just enough detail to identify the meant sign and those with so much detail that the reader can reproduce the sign. This higher number of details is reflected in a higher number of parameters and symbols.
  Hence, we present eleven sign notation systems, starting by examining the handshape as the most concise parameter of sign language. We compare it in the context of notation systems for its suitability for our gamified learning app for sign language. A clear differentiation of the handshapes needed for American Sign Language is essential for qualitative feedback for the user. At the same time, a small number of handshapes should reduce the technical effort required for reliable recognition.

  **Keywords**: handshape identification, gesture recognition, sign language, sign notation systems, sign learning app

  **Comment**: Good for learning about different sign language notation systems, however we now determine the parameters/handshapes needed via the ASL-LEX database.
</details>

## To do
- https://sign-parametrization.netlify.app & https://github.com/serious-games-darmstadt/sign-parametrization
- https://github.com/serious-games-darmstadt/sign-visualizations
- https://sign-games.com & https://github.com/serious-games-darmstadt/sign-games
- https://github.com/serious-games-darmstadt/WLASL
- https://github.com/serious-games-darmstadt/leap_motion_and_data_glove_classifier
- https://github.com/serious-games-darmstadt/gesture-classifier

### Databases
- https://github.com/serious-games-darmstadt/dataglove_manus-prime-x_handshapes
- https://github.com/serious-games-darmstadt/dataglove_senso-glove-dk2_rps-gestures

### Theses
- https://github.com/serious-games-darmstadt/BA_signs_video_parametrization
- https://github.com/serious-games-darmstadt/BA_data_enrichment
- https://github.com/serious-games-darmstadt/BA_data_glove_asl
- https://github.com/serious-games-darmstadt/BA_augmented_finger_motion_data
- https://github.com/serious-games-darmstadt/MA_arm_posture_detection & https://github.com/serious-games-darmstadt/imu-controller
- [comment]: <> (wo sind die anderen MAs? Alle BAs hier?)
